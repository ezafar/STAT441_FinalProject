{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FE Strat:\n",
    "## Exploratory Data Analysis (EDA): Begin by understanding the data. Explore distributions, correlations, and relationships between features and the target variable.\n",
    "\n",
    "## Feature Importance: Done in the LGBM NB, Insights to follow\n",
    "\n",
    "## Feature Selection: We will do feature selection on the basis of importance(Model based feature selection)\n",
    "\n",
    "- However there are other ways to go about this\n",
    "- Correlation Analysis: Identify highly correlated features and consider removing one of them to reduce multicollinearity, similar to us removing redundant info features as I have mentioned below. We would ideally like to do a formal analysis, as many features seem to be correlated.\n",
    "- Recursive Feature Elimination: Use iterative model training to identify and remove less important features.\n",
    "- Domain Knowledge: Incorporate domain knowledge if available. Certain features might be inherently more important due to the nature of the problem.\n",
    "\n",
    "## Feature Engineering:\n",
    "- Encoding Categorical Variables: Seems to already be done\n",
    "- Creating Interaction Terms: Generate new features by combining existing features (e.g., multiplication, addition, division). We may need to do this, specifically for features that are country specific(Like education)\n",
    "- Transformations: Dont think we need this, since we do not have any significant predictors that can undergo numerical transforms like log, square etc.\n",
    "- Aggregations: Create features by aggregating data across groups or time periods. We may need to do this, see below for specifics\n",
    "- Feature Scaling: Scale numerical features to have similar ranges, this seems to be irrelevant to us as we do not have many numerical variables that are important\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Insights from Importance plot, Beginning our FE journey\n",
    "- NOTE: We can dive into eatch feature in- depth, however in the interest of time, I have focused on features/ feature classess that have shown up in the 50 most important for our full model\n",
    "- Most of the top importance features are directly linked to religon\n",
    "- V277 is one of the most important features, and is the date of interview - should we include this as an explanatory variable?\n",
    "- v52 vs v52_cs (Same question, shows up twice on the plot, might have redundancy there). It seems likely that v52_cs contains all the information V52 would, should find a way to verify this\n",
    "- v282 is interviewer number, and has high importance - should we include this as an explanatory variable? How well will our prediction be in the case we encounter a new interviewer, and one of our most important features is interviewer_number? We might be assigning high value to something out of our control in that case. A tradeoff needs to be seen, comparing models without this and with on the actual data\n",
    "- if we are using v261_ppp, do we need to use v_261(low importance, and I believe the _ppp version contains a better estimate of how income affects the prediction) \n",
    "- v279d_r is made up of v279a and v279b, we would want to remove them from our model\n",
    "- v226 and age are the same, (Year of birth vs age), hence we have a redundancy\n",
    "- v281a vs v281a_r: the _r version seems to be a mapping of the string explanatory variate v281a. We should only use the _r version\n",
    "- the v275 class of explanatory variables: We should use only 1 region code, I reccomend v275b_N2, as it seems the most granular and has the most unique values, although V275c_n2 seems to have the most importance in our full model\n",
    "- The v279 and v278 classes must be explored and experimented with: All have to do with time, duration of interviews. My initial feel is we have to use some combo of duration v279d_r, and begin time/end time, and combine them into 1 variate i.e: (begin_time, dur) or (dur, end_time). Also need to decide on granularity of minutes vs hours. Several members of these classes show up as important features, and must be dealt with\n",
    "- v243 class: All of these variates deal with education, v243_cs is most important, but we must look at which ones to keep and which ones to not.\n",
    "- v262 deals with fathers education: Whatever we do for v243, might also apply here\n",
    "- even though v242 shows up as important, v242_r maybe a better predictor since it has buckets which eliminate the non labeled data present in v242\n",
    "- the v246 class must be looked at, maybe we should only use the most important v246_SIOPS, since others may have redundant information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Next Steps\n",
    "- Deal with the redundant features among the top features, detailed above. We may have to fit a variety of models to figure out what is best, using a subset of similar features.\n",
    "- create an aggregation/new feature for the v279 and v278 classess to better understand the impact of time/duration on our predictions. Our best bet is to create multiple variants, and see which one is most important, and only use that\n",
    "- Replot the the importance plot, and see what changes. We may see new important features pop up, and would have to deal with them accordingly\n",
    "- Note that this is not comprehensive, and since we have ~500 features I may have missed some things, and we can keep iterating to do it better. However, we should probably limit ourselves to 1-2 iterations of this process."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
