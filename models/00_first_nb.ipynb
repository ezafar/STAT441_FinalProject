{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NgKNcJyDs4G6"
      },
      "source": [
        "https://www.kaggle.com/competitions/w2024-kaggle-contest\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "cYQnPLvjnODE"
      },
      "outputs": [],
      "source": [
        "# Import Statements\n",
        "import os\n",
        "import pandas as pd\n",
        "import lightgbm as lgb\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# Import Local funcs\n",
        "import sys\n",
        "sys.path.append('../')\n",
        "from utils.utils import *"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TwZrTEW2nqcj",
        "outputId": "eee8f39c-6ab1-46b6-a670-a42818e1e4b7"
      },
      "outputs": [],
      "source": [
        "X, y = get_training()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CfN-FUtRyfpW"
      },
      "outputs": [],
      "source": [
        "# Creating a parameter grid\n",
        "param_grid = {\n",
        "    'boosting_type': ['gbdt'],\n",
        "    'objective': ['multiclass'],\n",
        "    'metric': ['multi_logloss'],         # any ideas , would choosing appropriate function help in better results?\n",
        "    \n",
        "    'num_leaves': [15, 31, 50],           # Number of leaves in one tree\n",
        "    'learning_rate': [0.05, 0.1, 0.2],    # Learning rate\n",
        "    'feature_fraction': [0.8, 0.9, 1.0],  # Percentage of features to consider for each tree\n",
        "    'bagging_fraction': [0.8, 0.9, 1.0],  # Percentage of data to use for each boosting iteration\n",
        "    'bagging_freq': [5],                  # Frequency for bagging\n",
        "    'verbose': [1]\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_RsQawrQtmry"
      },
      "outputs": [],
      "source": [
        "# Drop Object data types\n",
        "X = drop_objects(X)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "M60tIuTY0M0t",
        "outputId": "6fa1f0fe-61b2-4efd-e1c3-1f844e691350"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 81 candidates, totalling 405 fits\n"
          ]
        }
      ],
      "source": [
        "# Find parameters with lightgbm\n",
        "model_lgb = lgb.LGBMClassifier()\n",
        "grid_search = GridSearchCV(model_lgb, param_grid, cv=5, n_jobs=-1, verbose=1)\n",
        "grid_search.fit(X, y)\n",
        "print(grid_search.best_params_)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kT2TMU5dvQxL",
        "outputId": "43c48659-db23-43bf-93f6-c8720c46941d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
            "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
            "Prediction of X_train: [2 2 4 ... 4 3 3]\n",
            "Score: 0.7364375\n"
          ]
        }
      ],
      "source": [
        "# Make prediction of X_train and find score\n",
        "y_pred = model_lgb.predict(X_train)\n",
        "score = model_lgb.score(X_train, y_train)\n",
        "print('Prediction of X_train:', y_pred)\n",
        "print('Score:', score)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4jRK20cvFirg",
        "outputId": "9eb4cbe9-c8cd-4863-8bc6-e914115ec5d6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "v262_8cat     v262_EISCED       0.999998\n",
              "v263_EISCED   v263_8cat         0.999997\n",
              "v262_ISCED_2  v262_ISCED_2b     0.999986\n",
              "v243_edulvlb  v243_edulvlb_2    0.999979\n",
              "v263_ISCED_2  v263_ISCED_2b     0.999978\n",
              "                                  ...   \n",
              "v179_DK       v176_DK           0.974104\n",
              "v181_DK       v177_DK           0.973999\n",
              "v176_DK       v177_DK           0.973833\n",
              "v181_DK       v179_DK           0.973674\n",
              "v262_cs_GB1   v262_cs_GB2       0.973188\n",
              "Length: 100, dtype: float64"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Finding all correlation for all columns with each other find the top 100\n",
        "correlation_matrix = X.corr()\n",
        "top_100_correlations = correlation_matrix.unstack().sort_values(ascending=False).drop_duplicates()\n",
        "top_100_correlations = top_100_correlations[1:101]\n",
        "top_100_correlations"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
